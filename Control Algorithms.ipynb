{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Imports\n",
    "import gym\n",
    "import numpy as np\n",
    "np.random.seed(123)\n",
    "import time\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "import algorithmsv2\n",
    "import cartpole_reward\n",
    "import estimate_L\n",
    "import observables\n",
    "import tf_algorithmsv2\n",
    "\n",
    "#%% Functions\n",
    "def rho(u, o='unif', a=0, b=1):\n",
    "    if o == 'unif':\n",
    "        return 1 / ( b - a )\n",
    "    if o == 'normal':\n",
    "        return np.exp( -u**2 / 2 ) / ( np.sqrt( 2 * np.pi ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_0 = np.load('../../random-agent/cartpole-states-0.npy').T\n",
    "X_1 = np.load('../../random-agent/cartpole-states-1.npy').T\n",
    "Y_0 = np.load('../../random-agent/cartpole-next-states-0.npy').T\n",
    "Y_1 = np.load('../../random-agent/cartpole-next-states-1.npy').T\n",
    "X_data = { 0: X_0, 1: X_1 }\n",
    "Y_data = { 0: Y_0, 1: Y_1 }\n",
    "\n",
    "X = np.append(X_data[0], X_data[1], axis=1)\n",
    "Y = np.append(Y_data[0], Y_data[1], axis=1)\n",
    "U = np.empty([1,X.shape[1]])\n",
    "for i in range(X_data[0].shape[1]):\n",
    "    U[:,i] = [0]\n",
    "for i in range(X_data[1].shape[1]):\n",
    "    U[:,i+X_data[0].shape[1]] = [1]\n",
    "\n",
    "dim_x = X.shape[0] # dimension of each data point (snapshot)\n",
    "dim_u = U.shape[0] # dimension of each action\n",
    "N = X.shape[1] # number of data points (snapshots)\n",
    "\n",
    "#%% Matrix builder functions\n",
    "order = 2\n",
    "phi = observables.monomials(order)\n",
    "psi = observables.monomials(order)\n",
    "\n",
    "#%% Compute Phi and Psi matrices + dimensions\n",
    "Phi_X = phi(X)\n",
    "Phi_Y = phi(Y)\n",
    "Psi_U = psi(U)\n",
    "\n",
    "dim_phi = Phi_X.shape[0]\n",
    "dim_psi = Psi_U.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute estimate of K tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Build kronMatrix\n",
    "kronMatrix = np.empty((dim_psi * dim_phi, N))\n",
    "for i in range(N):\n",
    "    kronMatrix[:,i] = np.kron(Psi_U[:,i], Phi_X[:,i])\n",
    "\n",
    "#%% Estimate M and B matrices\n",
    "M = estimate_L.ols(kronMatrix.T, Phi_Y.T).T\n",
    "print(\"M shape:\", M.shape)\n",
    "assert M.shape == (dim_phi, dim_phi * dim_psi)\n",
    "\n",
    "B = estimate_L.ols(Phi_X.T, X.T)\n",
    "assert B.shape == (dim_phi, X.shape[0])\n",
    "\n",
    "#%% Reshape M into K tensor\n",
    "K = np.empty((dim_phi, dim_phi, dim_psi))\n",
    "for i in range(dim_phi):\n",
    "    K[i] = M[i].reshape((dim_phi,dim_psi), order='F')\n",
    "\n",
    "def K_u(K, u):\n",
    "    if len(u.shape) == 1:\n",
    "        u = u.reshape(-1,1) # assume transposing row vector into column vector\n",
    "    # u must be column vector\n",
    "    return np.einsum('ijz,z->ij', K, psi(u)[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Control Algorithms 10/28/2021\n",
    "### Notebook that covers our current implementations of control and aims to be used in fixing the problems with the gradient explosion\n",
    "\n",
    "## Learning Optimal Policy via Directly Minimizing Bellman Error\n",
    "This is based on section 5 in the [overleaf writeup](https://www.overleaf.com/project/6155ef2f57f2b6a1e034b696)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_U = np.array([[0,1]])\n",
    "u_bounds = [0,1]\n",
    "learning_rate = 0.0001\n",
    "w = np.ones([dim_phi])\n",
    "\n",
    "def cost(x,u):\n",
    "    return -cartpole_reward.defaultCartpoleReward(x,u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expressing Bellman Error:\n",
    "$$\n",
    "\\begin{align*}\n",
    "    w^{\\top}\\phi(x) - \\min_{\\pi: x\\mapsto \\Delta(A)} \\left[  \\mathbb{E}_{u\\sim \\pi(x)} \\left[ c(x,u) + \\ln\\pi(u | x) + w^{\\top} K(I, I, \\psi(u)) \\phi(x) \\right] \\right].\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "### Policy Expression:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\pi(u | x) = \\exp\\left( - \\left( c(x,u) + w^{\\top} K(I,I, \\psi(u)) \\phi(x)   \\right)  \\right) / Z_x,\n",
    "\\end{align}\n",
    "$$\n",
    "In the next block, we show our coded implementation of the policy expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner_pi_u(u, x):\n",
    "    K_u_const = K_u(K, psi(u)[:,0])\n",
    "    inner_pi_u = (-learning_rate * (cost(x, u) + w @ K_u_const @ phi(x)))[0]\n",
    "    return inner_pi_u\n",
    "\n",
    "def pi_u(u, x):\n",
    "    inner = inner_pi_u(u,x)\n",
    "    return np.exp(inner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expressing Bellman Error over a dataset:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\min_{w: \\|w\\|_2 \\leq W} \\sum_{i=1}^N \\left( w^{\\top}\\phi(x) - \\min_{\\pi(\\cdot | s)} \\left[ \\mathbb{E}_{u\\sim \\pi(x)} \\left[ c(x,u) + \\ln\\pi(u|s) +  w^{\\top} K(I, I, \\psi(u)) \\phi(x) \\right] \\right] \\right)^2\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discreteBellmanError():\n",
    "    total = 0\n",
    "    for i in range(X.shape[1]):\n",
    "        x = X[:,i].reshape(-1,1)\n",
    "        phi_x = phi(x)[:,0]\n",
    "\n",
    "        inner_pi_us = []\n",
    "        for u in U.T:\n",
    "            u = u.reshape(-1,1)\n",
    "            inner_pi_us.append(inner_pi_u(u, x))\n",
    "\n",
    "        inner_pi_us = np.real(inner_pi_us)\n",
    "        max_inner_pi_u = np.max(inner_pi_us)\n",
    "        max_inner_pi_u_index = np.argmax(inner_pi_us)\n",
    "        inner_pi_us[max_inner_pi_u_index] = 0.0\n",
    "        pi_us = np.exp(inner_pi_us)\n",
    "        Z_x = np.sum(pi_us)\n",
    "\n",
    "        expectation_u = 0\n",
    "        for i,u in enumerate(U.T):\n",
    "            u = u.reshape(-1,1)\n",
    "            pi = pi_us[i] / (Z_x - max_inner_pi_u)\n",
    "            K_u_const = K_u(K, psi(u)[:,0])\n",
    "            expectation_u += ( cost(x, u) - np.log(pi) - w @ K_u_const @ phi_x ) * pi\n",
    "        total += np.power(( w @ phi_x - expectation_u ), 2)\n",
    "\n",
    "    return total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to minimize the ojective function above, we will run some sort of gradient descent algorithm, in this case, SGD (stochastic gradient descent).\n",
    "\n",
    "The gradient of the objective function is as follows:\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\nabla_{w} := \\left( w^{\\top}\\phi(x) - \\left[ \\mathbb{E}_{u\\sim \\pi(x)} \\left[ c(x,u) + \\ln\\pi(u|s) +  w^{\\top} K(I, I, \\psi(u)) \\phi(x) \\right] \\right] \\right)\\left[ \\phi(x) -  \\mathbb{E}_{u\\sim \\pi(\\cdot | x)}  K(I, I, \\psi(u)) \\phi(x)  \\right].\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Our programatic implementation takes advantage of importance weighting as well as control sampling to get an unbiased estimate of the above formulation\n",
    "$$\n",
    "\\begin{align}\n",
    "\\widetilde\\nabla_{w} = &  \\left( w^{\\top}\\phi(x) - \\left[  \\frac{ \\pi(u_1|x) }{\\rho(u_1)} \\left[ c(x,u_1) + \\ln\\pi(u_1|s) +  w^{\\top} K(I, I, \\psi(u_1)) \\phi(x) \\right] \\right] \\right)\\\\\n",
    "& \\qquad  \\cdot \\left[ \\phi(x) -   \\frac{ \\pi(u_2|x) }{\\rho(u)}  K(I, I, \\psi(u_2)) \\phi(x)  \\right].\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u1 = All_U[:, np.random.choice(np.arange(All_U.shape[1]))].reshape(-1,1)\n",
    "u2 = All_U[:, np.random.choice(np.arange(All_U.shape[1]))].reshape(-1,1)\n",
    "x1 = X[:, np.random.choice(np.arange(X.shape[1]))].reshape(-1,1)\n",
    "psi_u1 = psi(u1)[:,0]\n",
    "psi_u2 = psi(u2)[:,0]\n",
    "phi_x1 = phi(x1)\n",
    "\n",
    "nabla_w = (w @ phi_x1 - ((pi_u(u1, x1) / rho(u1, a=u_bounds[0], b=u_bounds[1])) * (cost(x1, u1) + np.log(pi_u(u1, x1)) + w @ K_u(K, psi_u1) @ phi_x1))) \\\n",
    "            * (phi_x1 - (pi_u(u2, x1) / rho(u2, a=u_bounds[0], b=u_bounds[1])) * K_u(K, psi_u2) @ phi_x1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = w - (learning_rate * nabla_w)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
