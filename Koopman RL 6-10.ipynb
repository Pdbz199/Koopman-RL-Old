{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Koopman RL Update (June 10th)\n",
    "\n",
    "The most recent updates involve testing of the efficacy of the multi-Koopman approach where we have one Koopman operator for each action in an action space. We hoped to see that our operators could approximate the dynamics of CartPole very well. It appears that this is, in fact, the case, and so we should be able to move forward with this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import estimate_L\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.kernel_approximation import RBFSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definitions and Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def l2_norm(true_state, predicted_state):\n",
    "    return np.sum(np.power(( true_state - predicted_state ), 2 ))\n",
    "\n",
    "X = np.load('random-agent/cartpole-states.npy').T\n",
    "Y = np.append(np.roll(X, -1, axis=1)[:,:-1], np.zeros((X.shape[0],1)), axis=1)\n",
    "U = np.load('random-agent/cartpole-actions.npy').reshape(1,-1)\n",
    "\n",
    "X_0 = np.load('random-agent/cartpole-states-0.npy').T\n",
    "Y_0 = np.load('random-agent/cartpole-next-states-0.npy').T\n",
    "X_1 = np.load('random-agent/cartpole-states-1.npy').T\n",
    "Y_1 = np.load('random-agent/cartpole-next-states-1.npy').T\n",
    "\n",
    "state_dim = X.shape[0]\n",
    "\n",
    "percent_training = 0.8\n",
    "train_ind = int(np.around(X.shape[1]*percent_training))\n",
    "X_train = X[:,:train_ind]\n",
    "Y_train = Y[:,:train_ind]\n",
    "train_inds = [\n",
    "    int(np.around(X_0.shape[1]*percent_training)),\n",
    "    int(np.around(X_1.shape[1]*percent_training))\n",
    "]\n",
    "X_0_train = X_0[:,:train_inds[0]]\n",
    "X_1_train = X_1[:,:train_inds[1]]\n",
    "Y_0_train = Y_0[:,:train_inds[0]]\n",
    "Y_1_train = Y_1[:,:train_inds[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The kernel approximator used for this system was the RBF Sampler from scikit learn which uses random fourier features to find a good radial basis function to use. The radial basis function kernel is defined as $$ K(\\mathbf{x},\\mathbf{x}') = \\text{exp} \\Bigg(-\\frac{||\\mathbf{x} - \\mathbf{x}'||^2}{2 \\sigma^2}\\Bigg) $$ Where $\\gamma = \\frac{1}{2 \\sigma^2}$. Since it requires a $\\gamma$ value, we have to calculate some good $\\gamma$ so that we are not just guessing. http://alex.smola.org/teaching/kernelcourse/day_2.pdf contains a slide on how to find such a $\\gamma$ using a so-called \"median trick\" that can be used as a good solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Median trick\n",
    "num_pairs = 1000\n",
    "pairwise_distances = []\n",
    "for _ in range(num_pairs):\n",
    "    i, j = np.random.choice(np.arange(X.shape[1]), 2)\n",
    "    x_i = X[:,i]\n",
    "    x_j = X[:,j]\n",
    "    pairwise_distances.append(np.linalg.norm(x_i - x_j))\n",
    "pairwise_distances = np.array(pairwise_distances)\n",
    "gamma = np.quantile(pairwise_distances, 0.9)\n",
    "\n",
    "# RBF Sampler\n",
    "rbf_feature = RBFSampler(gamma=gamma, random_state=1)\n",
    "X_features = rbf_feature.fit_transform(X)\n",
    "def psi(x):\n",
    "    return X_features.T @ x.reshape((state_dim,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Psi matrices\n",
    "def getPsiMatrix(psi, X):\n",
    "    k = psi(X[:,0].reshape(-1,1)).shape[0]\n",
    "    m = X.shape[1]\n",
    "    matrix = np.empty((k,m))\n",
    "    for col in range(m):\n",
    "        matrix[:, col] = psi(X[:, col])[:, 0]\n",
    "    return matrix\n",
    "\n",
    "Psi_X = getPsiMatrix(psi, X_train)\n",
    "Psi_Y = getPsiMatrix(psi, Y_train)\n",
    "\n",
    "Psi_X_0 = getPsiMatrix(psi, X_0_train)\n",
    "Psi_Y_0 = getPsiMatrix(psi, Y_0_train)\n",
    "Psi_X_1 = getPsiMatrix(psi, X_1_train)\n",
    "Psi_Y_1 = getPsiMatrix(psi, Y_1_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solve for the multiple Koopman operators using the following minimization problem: $\\textbf{min}_{K_u}|| \\Psi_Y^\\top - \\Psi_X^\\top K_u^\\top ||$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "K_0 = estimate_L.rrr(Psi_X_0.T, Psi_Y_0.T).T\n",
    "K_1 = estimate_L.rrr(Psi_X_1.T, Psi_Y_1.T).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find mapping operator $B$ such that $B^\\top \\psi(x) \\approx x$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "B = estimate_L.SINDy(Psi_X.T, X_train.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing that we wanted to check in our approach is how well one-step prediction worked. The results are slightly confusing since it isn't great at predicting one-step ahead. Even though it is not a great approximation, it is not terrible either.\n",
    "\n",
    "### One-step prediction error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "title = \"One-step prediction error:\"\n",
    "print()\n",
    "\n",
    "# data_point_index = 1000\n",
    "horizon = 1000\n",
    "norms = []\n",
    "# action_path = U[0, data_point_index:data_point_index+horizon]\n",
    "action_path = U[0, :horizon]\n",
    "# starting_point = int(np.around(np.random.rand() * X_train.shape[1]))\n",
    "starting_point = 1700\n",
    "true_state = X[:,starting_point]\n",
    "for h in range(horizon):\n",
    "    action = action_path[h]\n",
    "    psi_x = psi(true_state)\n",
    "    predicted_state = B.T @ K_0 @ psi_x if action == 0 else B.T @ K_1 @ psi_x\n",
    "    true_state = X[:,starting_point+h+1]\n",
    "\n",
    "    norm = l2_norm(true_state.reshape(-1,1), predicted_state)\n",
    "    norms.append(norm)\n",
    "\n",
    "print(\"Mean norm:\", np.mean(norms))\n",
    "plt.plot(norms, marker='.', linestyle='')\n",
    "plt.title(title)\n",
    "plt.ylabel('L2 Norm')\n",
    "plt.xlabel('Timestep')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we wanted to test was how far out into the future the multi-Koopman approach could predict before it started to deviate heavily from the ground-truth. It looks like it can predict approximately 800 steps ahead which is certainly sufficient for CartPole!\n",
    "\n",
    "### Prediction compounding error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "title = \"Prediction compounding error:\"\n",
    "print(title)\n",
    "\n",
    "env = gym.make('CartPole-v0')\n",
    "horizon = 1000\n",
    "num_trials = 1#000\n",
    "norms = []\n",
    "for i in range(num_trials):\n",
    "    action_path = [np.random.choice([0,1]) for i in range(horizon)]\n",
    "    trial_norms = []\n",
    "    true_state = env.reset()\n",
    "    predicted_state = true_state.copy()\n",
    "    for h in range(horizon):\n",
    "        action = action_path[h]\n",
    "        psi_x = psi(predicted_state)\n",
    "        predicted_state = B.T @ K_0 @ psi_x if action == 0 else B.T @ K_1 @ psi_x\n",
    "        true_state, ___, __, _ = env.step(action)\n",
    "\n",
    "        norm = l2_norm(true_state.reshape(-1,1), predicted_state)\n",
    "        trial_norms.append(norm)\n",
    "    norms.append(trial_norms)\n",
    "\n",
    "plt.plot(np.mean(norms, axis=0))\n",
    "plt.title(title)\n",
    "plt.ylabel('L2 Norm')\n",
    "plt.xlabel('Timestep')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we wanted to check how well our $B$ matrix actually works when trying to retrieve $x$ from $\\psi(x)$. The error is very, very low which is great to see.\n",
    "\n",
    "### Error for $\\psi(x) \\to x$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "title = \"Error for psi(x) -> x:\"\n",
    "print(title)\n",
    "\n",
    "# data_point_index = 1000\n",
    "horizon = 1000\n",
    "norms = []\n",
    "# action_path = U[0, data_point_index:data_point_index+horizon]\n",
    "action_path = U[0, :horizon]\n",
    "# starting_point = int(np.around(np.random.rand() * X_train.shape[1]))\n",
    "starting_point = -1000\n",
    "true_states = X[:,starting_point:]\n",
    "for true_state in true_states.T:\n",
    "    true_state = true_state.reshape(-1,1)\n",
    "    projected_state = B.T @ psi(true_state)\n",
    "\n",
    "    norm = l2_norm(true_state, projected_state)\n",
    "    norms.append(norm)\n",
    "\n",
    "print(\"Mean norm:\", np.mean(norms))\n",
    "plt.plot(norms, marker='.', linestyle='')\n",
    "plt.title(title)\n",
    "plt.ylabel('L2 Norm')\n",
    "plt.xlabel('Timestep')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps the most important metric is the error in predicting the next lifted state $\\psi(x)'$ from $\\psi(x)$. The error is not too bad based on the graph which is good news.\n",
    "\n",
    "### Error for $\\psi(x) \\to \\psi(x)'$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Koopman from psi(x) -> psi(x)'\n",
    "# || Y     - X B               ||\n",
    "# || Psi_Y_i   - K Psi_X_i     ||\n",
    "# || Psi_Y_i.T - Psi_X_i.T K.T ||\n",
    "K_0 = estimate_L.rrr(Psi_X_0.T, Psi_Y_0.T).T\n",
    "K_1 = estimate_L.rrr(Psi_X_1.T, Psi_Y_1.T).T\n",
    "\n",
    "horizon = 1000\n",
    "action_path = U[0, -horizon:]\n",
    "norms = []\n",
    "true_states = X[:, -horizon:]\n",
    "for h in range(horizon):\n",
    "    action = action_path[h]\n",
    "    true_state = true_states[:,h].reshape(-1,1)\n",
    "    predicted_state = K_0 @ psi(true_state) if action == 0 else K_1 @ psi(true_state)\n",
    "\n",
    "    norm = l2_norm(psi(true_state), predicted_state)\n",
    "    norms.append(norm)\n",
    "\n",
    "print(\"Mean norm:\", np.mean(norms))\n",
    "plt.plot(norms, marker='.', linestyle='')\n",
    "plt.title(\"Error for psi(x) -> psi(x)':\")\n",
    "plt.ylabel('L2 Norm')\n",
    "plt.xlabel('Timestep')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also wanted to see how well going directly from $\\psi(x)$ to $x'$ would work. Perhaps unsurprisingly, it has roughly the same error as going from $\\psi(x) \\to \\psi(x)'$, but is slightly worse and technically, this operator would not be considered a \"Koopman\" operator.\n",
    "\n",
    "### Error for $\\psi(x) \\to x'$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "title = \"Error for psi(x) -> x':\"\n",
    "print(title)\n",
    "\n",
    "# Operator from psi(x) -> x'\n",
    "# || Y     - X B           ||\n",
    "# || Y_i   - K Psi_X_i     ||\n",
    "# || Y_i.T - Psi_X_i.T K.T ||\n",
    "K_0 = estimate_L.rrr(Psi_X_0.T, Y_0_train.T).T\n",
    "K_1 = estimate_L.rrr(Psi_X_1.T, Y_1_train.T).T\n",
    "\n",
    "horizon = 1000\n",
    "action_path = U[0, -horizon:]\n",
    "norms = []\n",
    "true_states = X[:, -horizon:]\n",
    "for h in range(horizon):\n",
    "    action = action_path[h]\n",
    "    true_state = true_states[:,h].reshape(-1,1)\n",
    "    predicted_state = K_0 @ psi(true_state) if action == 0 else K_1 @ psi(true_state)\n",
    "\n",
    "    norm = l2_norm(true_state, predicted_state)\n",
    "    norms.append(norm)\n",
    "\n",
    "print(\"Mean norm:\", np.mean(norms))\n",
    "plt.plot(norms, marker='.', linestyle='')\n",
    "plt.title(\"Error for psi(x) -> x':\")\n",
    "plt.ylabel('L2 Norm')\n",
    "plt.xlabel('Timestep')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the hopes that the residual error could be much easier to predict, we were interested in computing that error. Predicting future states with the residual would mean predicting from $\\psi(x)$ to $\\psi(x)' - \\psi(x)$, and then adding $\\psi(x)$ back. Unfortunately this did not work well, but since previous errors were good enough, we should be good to use the traditional Koopman solution without much issue.\n",
    "\n",
    "### Residual error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "title = \"Residual error:\"\n",
    "print(title)\n",
    "\n",
    "# residuals_0 = Psi_Y_0 - Psi_X_0\n",
    "# residuals_1 = Psi_Y_1 - Psi_X_1\n",
    "residuals = Psi_Y - Psi_X\n",
    "# psi(x) -> psi(x') - psi(x)\n",
    "# K_0 = estimate_L.rrr(Psi_X_0.T, residuals_0.T).T\n",
    "# K_1 = estimate_L.rrr(Psi_X_1.T, residuals_1.T).T\n",
    "K = estimate_L.rrr(Psi_X.T, residuals.T).T\n",
    "\n",
    "horizon = 1000\n",
    "action_path = U[0, -horizon:]\n",
    "norms = []\n",
    "true_states = X_train[:, -horizon:]\n",
    "true_states_prime = Y_train[:, -horizon:]\n",
    "for h in range(horizon):\n",
    "    action = action_path[h]\n",
    "\n",
    "    true_state = true_states[:,h].reshape(-1,1)\n",
    "    psi_x = psi(true_state)\n",
    "\n",
    "    predicted_residual = K @ psi_x\n",
    "    predicted_psi_x_prime = psi_x + predicted_residual\n",
    "    predicted_x_prime = B.T @ predicted_psi_x_prime\n",
    "\n",
    "    true_x_prime = true_states_prime[:,h].reshape(-1,1)\n",
    "\n",
    "    norm = l2_norm(true_x_prime, predicted_x_prime)\n",
    "    norms.append(norm)\n",
    "\n",
    "print(\"Mean norm:\", np.mean(norms))\n",
    "plt.plot(norms, marker='.', linestyle='')\n",
    "plt.title(title)\n",
    "plt.ylabel('L2 Norm')\n",
    "plt.xlabel('Timestep')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
